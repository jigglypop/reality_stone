"""
Reality Stone ê°„ë‹¨í•œ ê³ ê¸‰ ì••ì¶• í…ŒìŠ¤íŠ¸
SVD + FFT Hybrid ì••ì¶• ê¸°ëŠ¥ë§Œ ê²€ì¦

ëª©í‘œ: ë†’ì€ ì••ì¶•ë¥  + ì •í™•ë„ ë³´ì¡´ í™•ì¸
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import copy
import warnings
warnings.filterwarnings("ignore")


class SimpleHybridSuperLayer(nn.Module):
    """ê°„ë‹¨í•œ SVD + FFT Hybrid ì••ì¶• ê¸°ìˆ  ê¸°ë°˜ Super Layer"""
    
    def __init__(self, mlp_layers, layer_indices, svd_rank_ratio=0.5, fft_quality=0.95):
        super().__init__()
        
        self.layer_indices = layer_indices
        self.svd_rank_ratio = svd_rank_ratio
        self.fft_quality = fft_quality
        
        print(f"\nğŸ”¬ Simple Hybrid Super Layer (SVD + FFT)")
        print(f"   ìœµí•© ë ˆì´ì–´: {layer_indices}")
        print(f"   SVD rank ratio: {svd_rank_ratio}")
        print(f"   FFT í’ˆì§ˆ: {fft_quality:.1%}")
        
        # ê°€ì¤‘ì¹˜ ìˆ˜ì§‘
        all_c_fc_weights = [mlp.c_fc.weight.data.clone() for mlp in mlp_layers]
        all_c_proj_weights = [mlp.c_proj.weight.data.clone() for mlp in mlp_layers]
        
        # Hybrid ì••ì¶• ì ìš©
        self.c_fc_U, self.c_fc_S, self.c_fc_V = self._create_hybrid_compressed_layer(
            all_c_fc_weights, "c_fc"
        )
        
        self.c_proj_U, self.c_proj_S, self.c_proj_V = self._create_hybrid_compressed_layer(
            all_c_proj_weights, "c_proj"
        )
        
        # ë°”ì´ì–´ìŠ¤ ì²˜ë¦¬
        if mlp_layers[0].c_fc.bias is not None:
            all_c_fc_bias = torch.stack([mlp.c_fc.bias.data for mlp in mlp_layers])
            self.c_fc_bias = nn.Parameter(torch.mean(all_c_fc_bias, dim=0))
        else:
            self.register_parameter('c_fc_bias', None)
            
        if mlp_layers[0].c_proj.bias is not None:
            all_c_proj_bias = torch.stack([mlp.c_proj.bias.data for mlp in mlp_layers])
            self.c_proj_bias = nn.Parameter(torch.mean(all_c_proj_bias, dim=0))
        else:
            self.register_parameter('c_proj_bias', None)
        
        self.activation = nn.GELU()
        
        # ì••ì¶•ë¥  ê³„ì‚°
        original_total = sum(w.numel() for w in all_c_fc_weights + all_c_proj_weights)
        compressed_total = (self.c_fc_U.numel() + self.c_fc_S.numel() + self.c_fc_V.numel() + 
                          self.c_proj_U.numel() + self.c_proj_S.numel() + self.c_proj_V.numel())
        
        self.compression_ratio = compressed_total / original_total
        
        print(f"   ğŸ¯ Hybrid ì••ì¶• ì™„ë£Œ:")
        print(f"   ì›ë³¸ íŒŒë¼ë¯¸í„°: {original_total:,}")
        print(f"   ì••ì¶• íŒŒë¼ë¯¸í„°: {compressed_total:,}")
        print(f"   ì••ì¶•ë¥ : {self.compression_ratio:.3f} ({(1-self.compression_ratio)*100:.1f}% ì ˆì•½)")
        
    def _create_hybrid_compressed_layer(self, weight_list, layer_type):
        """SVD + FFT í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶•"""
        
        print(f"\n   ğŸ”¬ {layer_type} Hybrid ì••ì¶• ì¤‘...")
        
        # 1. FFT ê¸°ë°˜ ë ˆì´ì–´ ìœµí•©
        fft_layers = []
        for weight in weight_list:
            weight_fft = torch.fft.fft2(weight.float())
            fft_layers.append(weight_fft)
            
        fft_stack = torch.stack(fft_layers, dim=0)
        magnitude_stack = torch.abs(fft_stack)
        avg_magnitude = torch.mean(magnitude_stack, dim=0)
        
        # ì¤‘ìš”í•œ ì£¼íŒŒìˆ˜ ì„±ë¶„ ì„ íƒ
        h, w = avg_magnitude.shape
        magnitude_flat = avg_magnitude.flatten()
        sorted_indices = torch.argsort(magnitude_flat, descending=True)
        
        keep_coeffs = int(len(magnitude_flat) * self.fft_quality)
        important_indices = sorted_indices[:keep_coeffs]
        
        mask = torch.zeros_like(magnitude_flat, dtype=torch.bool)
        mask[important_indices] = True
        mask = mask.reshape(h, w)
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìœµí•©
        layer_weights = torch.linspace(0.5, 1.5, len(weight_list))
        layer_weights = layer_weights / layer_weights.sum()
        
        weighted_fft = torch.zeros_like(fft_stack[0])
        for i, weight in enumerate(layer_weights):
            weighted_fft += fft_stack[i] * weight * mask
        
        # IFFTë¡œ ë³µì›
        fused_weight = torch.fft.ifft2(weighted_fft).real
        
        # 2. SVD ì••ì¶• ì ìš©
        U, S, V = torch.svd(fused_weight)
        
        # rank ê³„ì‚° (ì—ë„ˆì§€ ê¸°ë°˜)
        energy = torch.cumsum(S**2, dim=0) / torch.sum(S**2)
        rank = torch.sum(energy < self.svd_rank_ratio).item() + 1
        rank = max(rank, int(min(fused_weight.shape) * 0.1))
        
        print(f"   SVD rank: {min(fused_weight.shape)} â†’ {rank} ({rank/min(fused_weight.shape):.1%})")
        
        # ì••ì¶•ëœ ì„±ë¶„ë“¤
        U_compressed = U[:, :rank]
        S_compressed = S[:rank]
        V_compressed = V[:, :rank]
        
        return (nn.Parameter(U_compressed.to(weight_list[0].dtype).to(weight_list[0].device)),
                nn.Parameter(S_compressed.to(weight_list[0].dtype).to(weight_list[0].device)),
                nn.Parameter(V_compressed.to(weight_list[0].dtype).to(weight_list[0].device)))
        
    def forward(self, x):
        """Hybrid Super Layer ìˆœì „íŒŒ"""
        # c_fc: SVD ë³µì› í›„ ì ìš©
        c_fc_weight = torch.mm(self.c_fc_U * self.c_fc_S.unsqueeze(0), self.c_fc_V.T)
        h = F.linear(x, c_fc_weight.T, self.c_fc_bias)
        h = self.activation(h)
        
        # c_proj: SVD ë³µì› í›„ ì ìš©
        c_proj_weight = torch.mm(self.c_proj_U * self.c_proj_S.unsqueeze(0), self.c_proj_V.T)
        output = F.linear(h, c_proj_weight.T, self.c_proj_bias)
        
        return output


def apply_hybrid_compression(model, svd_ratio=0.5, fft_quality=0.95, target_layers=None):
    """í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶• ì ìš©"""
    
    print(f"\nğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶• ì ìš©")
    print(f"   SVD ratio: {svd_ratio}")
    print(f"   FFT í’ˆì§ˆ: {fft_quality:.1%}")
    
    total_layers = len(model.transformer.h)
    
    if target_layers is None:
        # í›„ë°˜ë¶€ ë ˆì´ì–´ë“¤ì„ ìœµí•© (ì ˆë°˜ë¶€í„°)
        target_layers = list(range(total_layers // 2, total_layers))
    
    print(f"   ìœµí•© ëŒ€ìƒ: {target_layers}")
    
    # MLPë“¤ ìˆ˜ì§‘
    mlp_layers = [model.transformer.h[i].mlp for i in target_layers]
    
    # Super Layer ìƒì„±
    super_layer = SimpleHybridSuperLayer(
        mlp_layers, target_layers, svd_ratio, fft_quality
    )
    
    # ì²« ë²ˆì§¸ ìœµí•© ë ˆì´ì–´ì— Super Layer ë°°ì¹˜
    model.transformer.h[target_layers[0]].mlp = super_layer
    
    # ë‚˜ë¨¸ì§€ ìœµí•© ë ˆì´ì–´ë“¤ ì œê±°
    for i in reversed(target_layers[1:]):
        del model.transformer.h[i]
    
    return model, super_layer.compression_ratio


def test_accuracy_preservation(model, tokenizer):
    """ì •í™•ë„ ë³´ì¡´ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ“Š ì •í™•ë„ í…ŒìŠ¤íŠ¸")
    
    tests = [
        ("í•œêµ­ì˜ ìˆ˜ë„ëŠ”", ["ì„œìš¸", "Seoul"]),
        ("ì•ˆë…•í•˜ì„¸ìš”", ["ì•ˆë…•", "ë°˜ê°‘", "ì¢‹"]), 
        ("ì¸ê³µì§€ëŠ¥", ["AI", "ê¸°ìˆ ", "ì»´í“¨í„°"]),
        ("ê¹€ì¹˜", ["ìŒì‹", "í•œêµ­", "ë¨¹"]),
        ("ì„œìš¸", ["í•œêµ­", "ìˆ˜ë„", "ë„ì‹œ"])
    ]
    
    correct = 0
    for prompt, expected_list in tests:
        try:
            inputs = tokenizer(prompt, return_tensors="pt")
            with torch.no_grad():
                outputs = model.generate(
                    inputs.input_ids,
                    max_length=len(inputs.input_ids[0]) + 10,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=tokenizer.eos_token_id
                )
            
            generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ê´€ë ¨ì„± ì²´í¬
            score = 1 if any(exp in generated for exp in expected_list) else 0
            correct += score
            
            print(f"   '{prompt}' â†’ '{generated[:40]}...' ({'âœ…' if score else 'âŒ'})")
            
        except Exception as e:
            print(f"   '{prompt}' â†’ ì˜¤ë¥˜: {e} (âŒ)")
    
    accuracy = correct / len(tests)
    print(f"   ì •í™•ë„: {accuracy:.1%}")
    
    return accuracy


def simple_advanced_compression_test():
    """ê°„ë‹¨í•œ ê³ ê¸‰ ì••ì¶• í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ¯ Reality Stone ê°„ë‹¨í•œ ê³ ê¸‰ ì••ì¶• í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print("   ëª©í‘œ: SVD + FFT Hybrid ì••ì¶• ê¸°ëŠ¥ ê²€ì¦")
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        model_name = "skt/kogpt2-base-v2"
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”©: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32)
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    original_params = sum(p.numel() for p in model.parameters())
    original_layers = len(model.transformer.h)
    
    print(f"\nğŸ“Š ì›ë³¸ ëª¨ë¸:")
    print(f"   ë ˆì´ì–´ ìˆ˜: {original_layers}")
    print(f"   íŒŒë¼ë¯¸í„°: {original_params:,}")
    print(f"   í¬ê¸°: {original_params * 4 / (1024**2):.1f}MB")
    
    # ì›ë³¸ ì •í™•ë„ ì¸¡ì •
    print(f"\nğŸ“‹ ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    original_accuracy = test_accuracy_preservation(model, tokenizer)
    
    # ë‹¤ì–‘í•œ ì••ì¶• ì„¤ì • í…ŒìŠ¤íŠ¸
    compression_configs = [
        {'name': 'Light Compression', 'svd_ratio': 0.8, 'fft_quality': 0.98, 'target_layers': [10, 11]},
        {'name': 'Medium Compression', 'svd_ratio': 0.6, 'fft_quality': 0.95, 'target_layers': [8, 9, 10, 11]},
        {'name': 'High Compression', 'svd_ratio': 0.4, 'fft_quality': 0.90, 'target_layers': [6, 7, 8, 9, 10, 11]},
        {'name': 'Extreme Compression', 'svd_ratio': 0.3, 'fft_quality': 0.85, 'target_layers': [4, 5, 6, 7, 8, 9, 10, 11]},
    ]
    
    best_result = None
    
    for config in compression_configs:
        print(f"\nğŸ¯ {config['name']}")
        print("=" * 60)
        
        try:
            # ëª¨ë¸ ë³µì‚¬ ë° ì••ì¶•
            compressed_model = copy.deepcopy(model)
            compressed_model, compression_ratio = apply_hybrid_compression(
                compressed_model, 
                svd_ratio=config['svd_ratio'],
                fft_quality=config['fft_quality'],
                target_layers=config['target_layers']
            )
            
            # ì••ì¶• í›„ í†µê³„
            compressed_params = sum(p.numel() for p in compressed_model.parameters())
            compressed_layers = len(compressed_model.transformer.h)
            actual_compression_ratio = compressed_params / original_params
            memory_saved = (original_params - compressed_params) * 4 / (1024**2)
            
            print(f"\nğŸ“Š ì••ì¶• í›„ ëª¨ë¸:")
            print(f"   ë ˆì´ì–´ ìˆ˜: {original_layers} â†’ {compressed_layers}")
            print(f"   íŒŒë¼ë¯¸í„°: {original_params:,} â†’ {compressed_params:,}")
            print(f"   ì‹¤ì œ ì••ì¶•ë¥ : {actual_compression_ratio:.3f}")
            print(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {memory_saved:.1f}MB ({(1-actual_compression_ratio)*100:.1f}%)")
            
            # ì••ì¶• ëª¨ë¸ ì •í™•ë„ í…ŒìŠ¤íŠ¸
            print(f"\nğŸ“‹ ì••ì¶• ëª¨ë¸ í…ŒìŠ¤íŠ¸")
            compressed_accuracy = test_accuracy_preservation(compressed_model, tokenizer)
            
            # ì •í™•ë„ ë³´ì¡´ìœ¨
            accuracy_retention = compressed_accuracy / original_accuracy if original_accuracy > 0 else 0
            
            print(f"\nğŸ“ˆ {config['name']} ê²°ê³¼:")
            print(f"   ì›ë³¸ ì •í™•ë„: {original_accuracy:.1%}")
            print(f"   ì••ì¶• ì •í™•ë„: {compressed_accuracy:.1%}")  
            print(f"   ì •í™•ë„ ë³´ì¡´: {accuracy_retention:.1%}")
            print(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {(1-actual_compression_ratio)*100:.1f}%")
            print(f"   ë ˆì´ì–´ ì ˆì•½: {original_layers - compressed_layers}ê°œ")
            
            # ì„±ê³¼ í‰ê°€
            high_compression = (1-actual_compression_ratio) >= 0.50  # 50%+ ì ˆì•½
            good_accuracy = accuracy_retention >= 0.80  # 80%+ ë³´ì¡´
            
            if high_compression and good_accuracy:
                best_result = {
                    'name': config['name'],
                    'compression_ratio': actual_compression_ratio,
                    'accuracy_retention': accuracy_retention,
                    'memory_saved': 1-actual_compression_ratio,
                    'layers_saved': original_layers - compressed_layers
                }
                print(f"   ğŸ‰ ìš°ìˆ˜í•œ ì„±ê³¼! (50%+ ì••ì¶• + 80%+ ì •í™•ë„)")
            
        except Exception as e:
            print(f"   âŒ ì••ì¶• ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    # ìµœì¢… ê²°ê³¼
    print(f"\nğŸ† ê°„ë‹¨í•œ ê³ ê¸‰ ì••ì¶• ìµœì¢… ê²°ê³¼")
    print("=" * 80)
    
    if best_result:
        print(f"ğŸ¥‡ ìµœê³  ì„±ê³¼: {best_result['name']}")
        print(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {best_result['memory_saved']:.1%}")
        print(f"   ì •í™•ë„ ë³´ì¡´: {best_result['accuracy_retention']:.1%}")
        print(f"   ë ˆì´ì–´ ì ˆì•½: {best_result['layers_saved']}ê°œ")
        print(f"   ì••ì¶•ë¥ : {best_result['compression_ratio']:.3f}")
        
        print(f"\nğŸ¯ í˜ì‹ ì  ì„±ê³¼:")
        print(f"   âœ… SVD + FFT Hybrid ì••ì¶• ì„±ê³µ")
        print(f"   âœ… êµ¬ì¡°ì  ì••ì¶•: ì—¬ëŸ¬ ë ˆì´ì–´ ìœµí•©")
        print(f"   âœ… ë†’ì€ ì••ì¶•ë¥  ë‹¬ì„±")
        print(f"   âœ… ì •í™•ë„ ìƒë‹¹ ë¶€ë¶„ ë³´ì¡´")
        
        print(f"\nğŸš€ SVD + FFT Hybrid ì••ì¶• ê¸°ìˆ  ê²€ì¦ ì™„ë£Œ!")
    else:
        print("ğŸ’ª ì••ì¶• ê¸°ëŠ¥ ê²€ì¦ ì™„ë£Œ, ë” ë‚˜ì€ íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")
    
    print(f"\nâœ… ê°„ë‹¨í•œ ê³ ê¸‰ ì••ì¶• í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    simple_advanced_compression_test() 