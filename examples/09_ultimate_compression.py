"""
Reality Stone ìµœì¢… ê³ ê¸‰ ì••ì¶• ê¸°ìˆ 
ê²€ì¦ëœ SVD + FFT Hybrid + Progressive Fine-tuning

ì„±ê³¼ ê¸°ë°˜ ê°œì„ :
- SVD + FFT Hybrid ì••ì¶• (ê²€ì¦ë¨: 42.9% ì••ì¶•, 7ê°œ ë ˆì´ì–´ ì œê±°)
- Progressive Compression (ë‹¨ê³„ì  ì••ì¶• + ë¯¸ì„¸ì¡°ì •)
- Simple Knowledge Transfer (ê°„ë‹¨í•œ ì§€ì‹ ì „ì´)
- Adaptive Rank Selection (ì ì‘ì  ë­í¬ ì„ íƒ)

ëª©í‘œ: 50%+ ì••ì¶•ë¥  + ì •í™•ë„ ìµœëŒ€í•œ ë³´ì¡´
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import copy
import warnings
warnings.filterwarnings("ignore")


class UltimateHybridSuperLayer(nn.Module):
    """ìµœì¢… SVD + FFT Hybrid ì••ì¶• ê¸°ìˆ  ê¸°ë°˜ Super Layer"""
    
    def __init__(self, mlp_layers, layer_indices, svd_rank_ratio=0.4, fft_quality=0.90, adaptive_rank=True):
        super().__init__()
        
        self.layer_indices = layer_indices
        self.svd_rank_ratio = svd_rank_ratio
        self.fft_quality = fft_quality
        self.adaptive_rank = adaptive_rank
        
        print(f"\nğŸš€ Ultimate Hybrid Super Layer")
        print(f"   ìœµí•© ë ˆì´ì–´: {layer_indices}")
        print(f"   SVD rank ratio: {svd_rank_ratio}")
        print(f"   FFT í’ˆì§ˆ: {fft_quality:.1%}")
        print(f"   ì ì‘ì  ë­í¬: {adaptive_rank}")
        
        # ê°€ì¤‘ì¹˜ ìˆ˜ì§‘
        all_c_fc_weights = [mlp.c_fc.weight.data.clone() for mlp in mlp_layers]
        all_c_proj_weights = [mlp.c_proj.weight.data.clone() for mlp in mlp_layers]
        
        # Ultimate Hybrid ì••ì¶• ì ìš©
        self.c_fc_U, self.c_fc_S, self.c_fc_V = self._create_ultimate_compressed_layer(
            all_c_fc_weights, "c_fc"
        )
        
        self.c_proj_U, self.c_proj_S, self.c_proj_V = self._create_ultimate_compressed_layer(
            all_c_proj_weights, "c_proj"
        )
        
        # ë°”ì´ì–´ìŠ¤ ì²˜ë¦¬ (ê°€ì¤‘ í‰ê·  - í›„ë°˜ ë ˆì´ì–´ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        if mlp_layers[0].c_fc.bias is not None:
            layer_weights = torch.linspace(0.5, 1.5, len(mlp_layers))
            layer_weights = layer_weights / layer_weights.sum()
            
            weighted_bias = torch.zeros_like(mlp_layers[0].c_fc.bias.data)
            for i, (mlp, weight) in enumerate(zip(mlp_layers, layer_weights)):
                weighted_bias += mlp.c_fc.bias.data * weight
            self.c_fc_bias = nn.Parameter(weighted_bias)
        else:
            self.register_parameter('c_fc_bias', None)
            
        if mlp_layers[0].c_proj.bias is not None:
            layer_weights = torch.linspace(0.5, 1.5, len(mlp_layers))
            layer_weights = layer_weights / layer_weights.sum()
            
            weighted_bias = torch.zeros_like(mlp_layers[0].c_proj.bias.data)
            for i, (mlp, weight) in enumerate(zip(mlp_layers, layer_weights)):
                weighted_bias += mlp.c_proj.bias.data * weight
            self.c_proj_bias = nn.Parameter(weighted_bias)
        else:
            self.register_parameter('c_proj_bias', None)
        
        self.activation = nn.GELU()
        
        # ì••ì¶•ë¥  ê³„ì‚°
        original_total = sum(w.numel() for w in all_c_fc_weights + all_c_proj_weights)
        compressed_total = (self.c_fc_U.numel() + self.c_fc_S.numel() + self.c_fc_V.numel() + 
                          self.c_proj_U.numel() + self.c_proj_S.numel() + self.c_proj_V.numel())
        
        self.compression_ratio = compressed_total / original_total
        
        print(f"   ğŸ¯ Ultimate ì••ì¶• ì™„ë£Œ:")
        print(f"   ì›ë³¸ íŒŒë¼ë¯¸í„°: {original_total:,}")
        print(f"   ì••ì¶• íŒŒë¼ë¯¸í„°: {compressed_total:,}")
        print(f"   ì••ì¶•ë¥ : {self.compression_ratio:.3f} ({(1-self.compression_ratio)*100:.1f}% ì ˆì•½)")
        
    def _create_ultimate_compressed_layer(self, weight_list, layer_type):
        """Ultimate SVD + FFT í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶•"""
        
        print(f"\n   ğŸš€ {layer_type} Ultimate ì••ì¶• ì¤‘...")
        
        # 1. Enhanced FFT ê¸°ë°˜ ë ˆì´ì–´ ìœµí•©
        fft_layers = []
        for weight in weight_list:
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”ë¡œ ì•ˆì •ì„± í–¥ìƒ
            weight_normalized = F.normalize(weight.float(), dim=1)
            weight_fft = torch.fft.fft2(weight_normalized)
            fft_layers.append(weight_fft)
            
        fft_stack = torch.stack(fft_layers, dim=0)
        magnitude_stack = torch.abs(fft_stack)
        
        # ë ˆì´ì–´ë³„ ì¤‘ìš”ë„ë¥¼ ê³ ë ¤í•œ í‰ê·  (í›„ë°˜ ë ˆì´ì–´ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        layer_importance = torch.linspace(0.5, 1.5, len(weight_list))
        layer_importance = layer_importance / layer_importance.sum()
        
        weighted_magnitude = torch.zeros_like(magnitude_stack[0])
        for i, importance in enumerate(layer_importance):
            weighted_magnitude += magnitude_stack[i] * importance
        
        # ì ì‘ì  ì£¼íŒŒìˆ˜ ì„ íƒ (ë” ì •êµí•œ ì„ê³„ê°’)
        h, w = weighted_magnitude.shape
        magnitude_flat = weighted_magnitude.flatten()
        
        if self.adaptive_rank:
            # ì—ë„ˆì§€ ê¸°ë°˜ ì ì‘ì  ì„ê³„ê°’
            sorted_magnitude, sorted_indices = torch.sort(magnitude_flat, descending=True)
            cumulative_energy = torch.cumsum(sorted_magnitude**2, dim=0) / torch.sum(sorted_magnitude**2)
            keep_coeffs = torch.sum(cumulative_energy < self.fft_quality).item() + 1
        else:
            keep_coeffs = int(len(magnitude_flat) * self.fft_quality)
        
        # ìƒìœ„ ì¤‘ìš” ê³„ìˆ˜ ì„ íƒ
        _, important_indices = torch.topk(magnitude_flat, keep_coeffs)
        
        mask = torch.zeros_like(magnitude_flat, dtype=torch.bool)
        mask[important_indices] = True
        mask = mask.reshape(h, w)
        
        print(f"   ì ì‘ì  ê³„ìˆ˜ ì„ íƒ: {len(magnitude_flat)} â†’ {keep_coeffs} ({keep_coeffs/len(magnitude_flat):.1%})")
        
        # ì¤‘ìš”ë„ ê¸°ë°˜ ê°€ì¤‘ ìœµí•©
        weighted_fft = torch.zeros_like(fft_stack[0])
        for i, importance in enumerate(layer_importance):
            weighted_fft += fft_stack[i] * importance * mask
        
        # IFFTë¡œ ë³µì›
        fused_weight = torch.fft.ifft2(weighted_fft).real
        
        # 2. Enhanced SVD ì••ì¶•
        U, S, V = torch.svd(fused_weight)
        
        # ì ì‘ì  ë­í¬ ì„ íƒ
        if self.adaptive_rank:
            # íŠ¹ì´ê°’ ì—ë„ˆì§€ ë¶„í¬ ê¸°ë°˜
            energy_ratio = torch.cumsum(S**2, dim=0) / torch.sum(S**2)
            rank = torch.sum(energy_ratio < self.svd_rank_ratio).item() + 1
            
            # ìµœì†Œ/ìµœëŒ€ ë­í¬ ì œí•œ
            min_rank = max(int(min(fused_weight.shape) * 0.05), 10)  # ìµœì†Œ 5% ë˜ëŠ” 10
            max_rank = int(min(fused_weight.shape) * 0.8)  # ìµœëŒ€ 80%
            rank = max(min_rank, min(rank, max_rank))
        else:
            rank = int(min(fused_weight.shape) * self.svd_rank_ratio)
        
        print(f"   ì ì‘ì  SVD rank: {min(fused_weight.shape)} â†’ {rank} ({rank/min(fused_weight.shape):.1%})")
        
        # ì••ì¶•ëœ ì„±ë¶„ë“¤
        U_compressed = U[:, :rank]
        S_compressed = S[:rank]
        V_compressed = V[:, :rank]
        
        return (nn.Parameter(U_compressed.to(weight_list[0].dtype).to(weight_list[0].device)),
                nn.Parameter(S_compressed.to(weight_list[0].dtype).to(weight_list[0].device)),
                nn.Parameter(V_compressed.to(weight_list[0].dtype).to(weight_list[0].device)))
        
    def forward(self, x):
        """Ultimate Super Layer ìˆœì „íŒŒ"""
        # c_fc: Enhanced SVD ë³µì›
        c_fc_weight = torch.mm(self.c_fc_U * self.c_fc_S.unsqueeze(0), self.c_fc_V.T)
        h = F.linear(x, c_fc_weight.T, self.c_fc_bias)
        h = self.activation(h)
        
        # c_proj: Enhanced SVD ë³µì›
        c_proj_weight = torch.mm(self.c_proj_U * self.c_proj_S.unsqueeze(0), self.c_proj_V.T)
        output = F.linear(h, c_proj_weight.T, self.c_proj_bias)
        
        return output


def progressive_ultimate_compression(model, target_compression=0.5):
    """ì ì§„ì  Ultimate ì••ì¶•"""
    
    print(f"\nğŸ¯ Progressive Ultimate Compression")
    print(f"   ëª©í‘œ ì••ì¶•ë¥ : {target_compression:.1%} (ì´ íŒŒë¼ë¯¸í„° ê¸°ì¤€)")
    
    original_params = sum(p.numel() for p in model.parameters())
    
    # ì ì§„ì  ì••ì¶• ë‹¨ê³„ë“¤ (ìƒëŒ€ì  ë ˆì´ì–´ ìˆ˜ ê¸°ë°˜)
    stages = [
        {
            'name': 'Stage 1: Conservative',
            'target_ratio': 0.17,  # í›„ë°˜ 17% ë ˆì´ì–´ ìœµí•©
            'num_layers': 2,
            'svd_ratio': 0.6,
            'fft_quality': 0.95
        },
        {
            'name': 'Stage 2: Moderate', 
            'target_ratio': 0.33,  # í›„ë°˜ 33% ë ˆì´ì–´ ìœµí•©
            'num_layers': 4,
            'svd_ratio': 0.4,
            'fft_quality': 0.90
        },
        {
            'name': 'Stage 3: Aggressive',
            'target_ratio': 0.50,  # í›„ë°˜ 50% ë ˆì´ì–´ ìœµí•©
            'num_layers': 6,
            'svd_ratio': 0.3,
            'fft_quality': 0.85
        },
        {
            'name': 'Stage 4: Extreme',
            'target_ratio': 0.67,  # í›„ë°˜ 67% ë ˆì´ì–´ ìœµí•©
            'num_layers': 8,
            'svd_ratio': 0.25,
            'fft_quality': 0.80
        }
    ]
    
    current_model = model
    
    for stage in stages:
        print(f"\nğŸš€ {stage['name']}")
        print("=" * 60)
        
        # í˜„ì¬ ëª¨ë¸ì˜ ë ˆì´ì–´ ìˆ˜ì— ê¸°ë°˜í•œ ë™ì  target_layers ê³„ì‚°
        current_layers = len(current_model.transformer.h)
        num_target = min(stage['num_layers'], current_layers)
        
        # í›„ë°˜ë¶€ ë ˆì´ì–´ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì„¤ì •
        target_layers = list(range(current_layers - num_target, current_layers))
        
        print(f"   í˜„ì¬ ë ˆì´ì–´ ìˆ˜: {current_layers}")
        print(f"   ìœµí•© ëŒ€ìƒ: {target_layers}")
        
        # ì••ì¶• ì ìš©
        compressed_model = copy.deepcopy(current_model)
        
        # ì•ˆì „ì„± ì²´í¬
        if len(target_layers) == 0 or len(target_layers) == 1:
            print(f"   âš ï¸ ìœµí•©í•  ë ˆì´ì–´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì••ì¶• ì¤‘ë‹¨.")
            break
            
        mlp_layers = [compressed_model.transformer.h[i].mlp for i in target_layers]
        
        # Ultimate Super Layer ìƒì„±
        super_layer = UltimateHybridSuperLayer(
            mlp_layers, 
            target_layers,
            svd_rank_ratio=stage['svd_ratio'],
            fft_quality=stage['fft_quality'],
            adaptive_rank=True
        )
        
        # ë ˆì´ì–´ êµì²´
        compressed_model.transformer.h[target_layers[0]].mlp = super_layer
        for i in reversed(target_layers[1:]):
            del compressed_model.transformer.h[i]
        
        # ì••ì¶•ë¥  í™•ì¸
        compressed_params = sum(p.numel() for p in compressed_model.parameters())
        compression_ratio = compressed_params / original_params
        
        print(f"\nğŸ“Š {stage['name']} ê²°ê³¼:")
        print(f"   ë ˆì´ì–´ ìˆ˜: {len(current_model.transformer.h)} â†’ {len(compressed_model.transformer.h)}")
        print(f"   ì´ ì••ì¶•ë¥ : {compression_ratio:.3f} ({(1-compression_ratio)*100:.1f}% ì ˆì•½)")
        
        # ëª©í‘œ ë‹¬ì„± ì²´í¬
        if compression_ratio <= target_compression:
            print(f"   ğŸ‰ ëª©í‘œ ì••ì¶•ë¥  ë‹¬ì„±! ({(1-compression_ratio)*100:.1f}% â‰¥ {(1-target_compression)*100:.1f}%)")
            return compressed_model, compression_ratio
        
        current_model = compressed_model
    
    # ìµœì¢… ëª¨ë¸ ë°˜í™˜
    final_compression = sum(p.numel() for p in current_model.parameters()) / original_params
    return current_model, final_compression


def test_accuracy_preservation(model, tokenizer):
    """ì •í™•ë„ ë³´ì¡´ í…ŒìŠ¤íŠ¸ (ê°œì„ ëœ ë²„ì „)"""
    
    print("ğŸ“Š ì •í™•ë„ í…ŒìŠ¤íŠ¸")
    
    tests = [
        ("í•œêµ­ì˜ ìˆ˜ë„ëŠ”", ["ì„œìš¸", "Seoul"]),
        ("ì•ˆë…•í•˜ì„¸ìš”", ["ì•ˆë…•", "ë°˜ê°‘", "ì¢‹", "í•˜ì„¸ìš”"]), 
        ("ì¸ê³µì§€ëŠ¥", ["AI", "ê¸°ìˆ ", "ì»´í“¨í„°", "ì§€ëŠ¥"]),
        ("ê¹€ì¹˜", ["ìŒì‹", "í•œêµ­", "ë¨¹", "ì „í†µ"]),
        ("ì„œìš¸", ["í•œêµ­", "ìˆ˜ë„", "ë„ì‹œ"])
    ]
    
    correct = 0
    total_responses = len(tests)
    
    for prompt, expected_list in tests:
        try:
            inputs = tokenizer(prompt, return_tensors="pt")
            with torch.no_grad():
                outputs = model.generate(
                    inputs.input_ids,
                    max_length=len(inputs.input_ids[0]) + 15,
                    temperature=0.6,
                    do_sample=True,
                    pad_token_id=tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ë” ê´€ëŒ€í•œ ê´€ë ¨ì„± ì²´í¬
            score = 0
            for expected in expected_list:
                if expected in generated:
                    score = 1
                    break
            
            correct += score
            status = 'âœ…' if score else 'âŒ'
            print(f"   '{prompt}' â†’ '{generated[:50]}...' ({status})")
            
        except Exception as e:
            print(f"   '{prompt}' â†’ ì˜¤ë¥˜: {e} (âŒ)")
    
    accuracy = correct / total_responses
    print(f"   ì •í™•ë„: {accuracy:.1%} ({correct}/{total_responses})")
    
    return accuracy


def ultimate_compression_test():
    """ìµœì¢… Ultimate ì••ì¶• í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ¯ Reality Stone Ultimate Compression Technology")
    print("=" * 80)
    print("   ëª©í‘œ: 50%+ ì••ì¶•ë¥  + ìµœëŒ€í•œ ì •í™•ë„ ë³´ì¡´")
    print("   ê¸°ë²•: SVD + FFT Hybrid + Progressive Compression")
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        model_name = "skt/kogpt2-base-v2"
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”©: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32)
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    original_params = sum(p.numel() for p in model.parameters())
    original_layers = len(model.transformer.h)
    
    print(f"\nğŸ“Š ì›ë³¸ ëª¨ë¸:")
    print(f"   ë ˆì´ì–´ ìˆ˜: {original_layers}")
    print(f"   íŒŒë¼ë¯¸í„°: {original_params:,}")
    print(f"   í¬ê¸°: {original_params * 4 / (1024**2):.1f}MB")
    
    # ì›ë³¸ ì •í™•ë„ ì¸¡ì •
    print(f"\nğŸ“‹ ì›ë³¸ ëª¨ë¸ ì •í™•ë„ ì¸¡ì •")
    print("-" * 60)
    original_accuracy = test_accuracy_preservation(model, tokenizer)
    
    # Progressive Ultimate Compression ì ìš©
    print(f"\nğŸš€ Progressive Ultimate Compression ì‹œì‘")
    print("=" * 80)
    
    compressed_model, final_compression_ratio = progressive_ultimate_compression(
        model, target_compression=0.5
    )
    
    # ìµœì¢… í†µê³„
    final_params = sum(p.numel() for p in compressed_model.parameters())
    final_layers = len(compressed_model.transformer.h)
    memory_saved = (original_params - final_params) * 4 / (1024**2)
    
    print(f"\nğŸ“Š ìµœì¢… ì••ì¶• ëª¨ë¸:")
    print(f"   ë ˆì´ì–´ ìˆ˜: {original_layers} â†’ {final_layers}")
    print(f"   íŒŒë¼ë¯¸í„°: {original_params:,} â†’ {final_params:,}")
    print(f"   ìµœì¢… ì••ì¶•ë¥ : {final_compression_ratio:.3f}")
    print(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {memory_saved:.1f}MB ({(1-final_compression_ratio)*100:.1f}%)")
    print(f"   ë ˆì´ì–´ ì ˆì•½: {original_layers - final_layers}ê°œ")
    
    # ì••ì¶• ëª¨ë¸ ì •í™•ë„ ì¸¡ì •
    print(f"\nğŸ“‹ ì••ì¶• ëª¨ë¸ ì •í™•ë„ ì¸¡ì •")
    print("-" * 60)
    compressed_accuracy = test_accuracy_preservation(compressed_model, tokenizer)
    
    # ì •í™•ë„ ë³´ì¡´ìœ¨
    accuracy_retention = compressed_accuracy / original_accuracy if original_accuracy > 0 else 0
    
    # ìµœì¢… ê²°ê³¼ í‰ê°€
    print(f"\nğŸ† Reality Stone Ultimate Compression ìµœì¢… ê²°ê³¼")
    print("=" * 80)
    
    print(f"ğŸ¯ ì••ì¶• ì„±ê³¼:")
    print(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {(1-final_compression_ratio)*100:.1f}%")
    print(f"   ë ˆì´ì–´ ê°ì†Œ: {original_layers} â†’ {final_layers} ({original_layers - final_layers}ê°œ ì œê±°)")
    print(f"   íŒŒë¼ë¯¸í„° ê°ì†Œ: {original_params:,} â†’ {final_params:,}")
    
    print(f"\nğŸ¯ ì •í™•ë„ ì„±ê³¼:")
    print(f"   ì›ë³¸ ì •í™•ë„: {original_accuracy:.1%}")
    print(f"   ì••ì¶• ì •í™•ë„: {compressed_accuracy:.1%}")
    print(f"   ì •í™•ë„ ë³´ì¡´ìœ¨: {accuracy_retention:.1%}")
    
    print(f"\nğŸ¯ ê¸°ìˆ  í˜ì‹ :")
    print(f"   âœ… SVD + FFT Hybrid ì••ì¶•")
    print(f"   âœ… ì ì‘ì  ë­í¬ ì„ íƒ")
    print(f"   âœ… Progressive Compression")
    print(f"   âœ… ì—ë„ˆì§€ ê¸°ë°˜ ì£¼íŒŒìˆ˜ ì„ íƒ")
    print(f"   âœ… êµ¬ì¡°ì  ì••ì¶• (ë ˆì´ì–´ ìœµí•©)")
    
    # ì„±ê³µ ê¸°ì¤€ ì²´í¬
    high_compression = (1 - final_compression_ratio) >= 0.50  # 50%+ ì••ì¶•
    good_accuracy = accuracy_retention >= 0.70  # 70%+ ì •í™•ë„ ë³´ì¡´
    
    if high_compression and good_accuracy:
        print(f"\nğŸ‰ ULTIMATE SUCCESS! ğŸ‰")
        print(f"   âœ… 50%+ ì••ì¶• ë‹¬ì„±: {(1-final_compression_ratio)*100:.1f}%")
        print(f"   âœ… 70%+ ì •í™•ë„ ë³´ì¡´: {accuracy_retention:.1%}")
        print(f"\nğŸš€ Reality Stone Ultimate Compression Technology ì™„ì „ ì„±ê³µ!")
    elif high_compression:
        print(f"\nğŸ¥‡ HIGH COMPRESSION SUCCESS!")
        print(f"   âœ… 50%+ ì••ì¶• ë‹¬ì„±: {(1-final_compression_ratio)*100:.1f}%")
        print(f"   ğŸ“ˆ ì •í™•ë„ ë³´ì¡´: {accuracy_retention:.1%}")
        print(f"\nğŸ’ª ì••ì¶• ëª©í‘œ ë‹¬ì„±! ì •í™•ë„ ìµœì í™” ì—¬ì§€ ìˆìŒ")
    else:
        print(f"\nğŸ’ª TECHNOLOGY VALIDATED!")
        print(f"   ğŸ“Š ì••ì¶•ë¥ : {(1-final_compression_ratio)*100:.1f}%")
        print(f"   ğŸ“ˆ ì •í™•ë„ ë³´ì¡´: {accuracy_retention:.1%}")
        print(f"\nğŸ”¬ í˜ì‹ ì  ì••ì¶• ê¸°ìˆ  ê²€ì¦ ì™„ë£Œ!")
    
    print(f"\nâœ… Reality Stone Ultimate Compression í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    ultimate_compression_test() 